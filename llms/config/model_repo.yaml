# This file contains default parameters for some MLLMs as per reported by the corresponding model creators.
# It is used for for:
# (i) abstract away some required parameters from calls when possible, such the `provider` to use
# (ii) loading default parameters when desired (see `get_model_attribute` in `llm_utils.py`)
# (iii) promptly checking some information about a model

models:
# Hugging Face
  blip2:
    model_path: 'Salesforce/blip2-flan-t5-xl'
    quant: ""
  
  qwen_2_5_vl_3b:
    model_path: 'Qwen/Qwen2.5-VL-3B-Instruct'

# Google Models
  gemini-1.5-flash-001:
    model_path: 'models/gemini-1.5-flash-001'
    provider: 'google'
    input_token_limit: 1000000
    output_token_limit: 8192
    temperature: 1.0
    max_temperature: 2.0
    top_p: 0.95
    top_k: 40
    # See examples/gemini_api.py to see how to get this information

  gemini-1.5-flash-002:
    model_path: 'models/gemini-1.5-flash-002'
    provider: 'google'
    input_token_limit: 1000000
    output_token_limit: 8192
    temperature: 1.0
    max_temperature: 2.0
    top_p: 0.95
    top_k: 40

  gemini-1.5-pro-001:
    model_path: 'models/gemini-1.5-pro-001'
    provider: 'google'
    input_token_limit: 2000000
    output_token_limit: 8192
    temperature: 1.0
    max_temperature: 2.0
    top_p: 0.95
    top_k: 40
  
  gemini-1.5-pro-002:
    model_path: 'models/gemini-1.5-pro-002'
    provider: 'google'
    input_token_limit: 2000000
    output_token_limit: 8192
    temperature: 1.0
    max_temperature: 2.0
    top_p: 0.95
    top_k: 40

  gemini-2.0-flash-exp:
    model_path: 'models/gemini-2.0-flash-exp'
    provider: 'google'

  gemini-2.0-flash-001:
    model_path: 'models/gemini-2.0-flash-001'
    provider: 'google'
    temperature: 1.0,
    max_temperature: 2.0,
    top_p: 0.95,
    top_k: 40

  gemini-2.0-pro-exp:
    model_path: 'models/gemini-2.0-pro-exp'
    provider: 'google'
    temperature: 1.0,
    max_temperature: 2.0,
    top_p: 0.95,
    top_k: 40

  gemini-2.0-flash-exp-image-generation:
    model_path: 'models/gemini-2.0-flash-exp-image-generation'
    provider: 'google'

  gemini-2.0-flash-thinking-exp-1219:
    model_path: 'models/gemini-2.0-flash-thinking-exp-1219'
    provider: 'google'

# OpenAI models
  gpt-3.5-turbo-0125:
    model_path: 'gpt-3.5-turbo-0125'
    provider: 'openai'
    input_token_limit: 16385 
    output_token_limit: 4096 
    tokenizer_path: gpt-3.5

  gpt-4o-2024-08-06:
    model_path: 'gpt-4o-2024-08-06'
    provider: 'openai'
    input_token_limit: 128000
    output_token_limit: 65536
    tokenizer_path: gpt-4o

  gpt-4o-mini-2024-07-18:
    model_path: 'gpt-4o-mini-2024-07-18'
    provider: 'openai'
    input_token_limit: 128000
    output_token_limit: 65536 
    tokenizer_path: gpt-4o
    
  gpt-4o-audio-preview:
    model_path: 'gpt-4o-audio-preview'
    provider: 'openai'

  gpt-o1-preview-2024-09-12:
    model_path: 'o1-preview-2024-09-12'
    provider: 'openai'
    input_token_limit: 128000
    output_token_limit: 32768 
    tokenizer_path: gpt-4

    
  o1-2024-12-17:
    model_path: 'o1-2024-12-17'
    provider: 'openai'
    input_token_limit: 128000
    output_token_limit: 32768 
    tokenizer_path: gpt-4

  o3-mini-2025-01-31:
    model_path: 'o3-mini-2025-01-31'
    provider: 'openai'
    input_token_limit: 128000
    output_token_limit: 32768 
    tokenizer_path: gpt-4


  computer-use-preview:
    model_path: computer-use-preview
    provider: openai
    mode: response

  computer-use-preview-2025-03-11:
    model_path: computer-use-preview-2025-03-11
    provider: openai
    mode: response

# Flan-t5
  flan-t5-base:
    model_path: 'google/flan-t5-base'
    tokenizer_path: 'google/flan-t5-base'
    provider: 'huggingface'

  flan-t5-small:
    model_path: 'google/flan-t5-small'
    tokenizer_path: 'google/flan-t5-small'
    provider: 'huggingface'

